{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9285a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import (LJLISTS_DIR, LOGS_DIR, \n",
    "                  WAVS_DIR, ENCODED_AUDIO_EN_DIR,\n",
    "                  DATA_DIR) \n",
    "\n",
    "version = \"v1\"\n",
    "grad_filename = \"grad_4750.pt\"\n",
    "version_dir = LOGS_DIR / version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import GradTTS\n",
    "from configs import params_v1\n",
    "\n",
    "model = GradTTS(\n",
    "        params_v1.n_ipa_feats,\n",
    "        params_v1.n_spks,\n",
    "        None if params_v1.n_spks == 1 else params_v1.spk_emb_dim, #spk_emb_dim\n",
    "        params_v1.n_enc_channels,\n",
    "        params_v1.filter_channels,\n",
    "        params_v1.filter_channels_dp,\n",
    "        params_v1.n_heads,\n",
    "        params_v1.n_enc_layers,\n",
    "        params_v1.enc_kernel,\n",
    "        params_v1.enc_dropout,\n",
    "        params_v1.window_size,\n",
    "        params_v1.n_feats,\n",
    "        params_v1.dec_dim,\n",
    "        params_v1.beta_min,\n",
    "        params_v1.beta_max,\n",
    "        params_v1.pe_scale,\n",
    "    )\n",
    "\n",
    "ckpt_state_dict = torch.load(version_dir / grad_filename,\n",
    "                  map_location=torch.device('cpu'))\n",
    "model.load_state_dict(ckpt_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54fd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_phnm import PhnmArticDataset, PhnmArticBatchCollate, PhnmBatchCollate\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "train_dataset = PhnmArticDataset(\n",
    "        params_v1.train_filelist_path,\n",
    "        data_root_dir=DATA_DIR,\n",
    "        load_coder=False,\n",
    "        merge_diphtongues=params_v1.merge_diphtongues,\n",
    "    )\n",
    "\n",
    "valid_dataset = PhnmArticDataset(\n",
    "    params_v1.valid_filelist_path,\n",
    "    data_root_dir=DATA_DIR,\n",
    "    load_coder=False,\n",
    "    merge_diphtongues=params_v1.merge_diphtongues,\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset.filepaths_list #= train_dataset.filepaths_list[:10]\n",
    "valid_dataset.filepaths_list #= valid_dataset.filepaths_list[:10]\n",
    "print(\"train_size\", len(train_dataset), \"valid_size\", len(valid_dataset))\n",
    "\n",
    "batch_collate = PhnmArticBatchCollate()\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=params_v1.batch_size,\n",
    "    collate_fn=batch_collate,\n",
    "    drop_last=True,\n",
    "    num_workers=3,\n",
    "    shuffle=False,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=params_v1.batch_size,\n",
    "    collate_fn=batch_collate,\n",
    "    drop_last=False,\n",
    "    num_workers=3,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4fe53e",
   "metadata": {},
   "source": [
    "## arttts_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_dir = DATA_DIR / \"LJSpeech-1.1\" / \"encoded_audio_en\" / \"emasrc\"\n",
    "avail_list = list(ema_dir.glob('*'))\n",
    "avail_list = [x.name[:-4] for x in avail_list]\n",
    "val_avail_samples = set(avail_list).intersection(set([e[0].split(\"/\")[-1][:-4] for e in valid_dataset.filepaths_list]))\n",
    "print(\"val_avail_samples\", len(val_avail_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fceec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import params_v1\n",
    "import numpy as np\n",
    "\n",
    "reorder_feats = params_v1.reorder_feats\n",
    "\n",
    "dataset = valid_dataset\n",
    "filepaths_list = dataset.filepaths_list[:2]\n",
    "batch_size = 2\n",
    "collator = PhnmBatchCollate()\n",
    "\n",
    "#model.eval()\n",
    "#with torch.no_grad():\n",
    "#    for i in range(0, len(filepaths_list), batch_size):\n",
    "#        batch_filepaths = filepaths_list[i:i + batch_size]\n",
    "#        phnm3_filepaths = [fp[1] for fp in batch_filepaths]\n",
    "#        phnm_embs = [{\"x\" : dataset.get_phnm_emb(phnm3_fp)} \n",
    "#                     for phnm3_fp in phnm3_filepaths]\n",
    "#        batch = collator(phnm_embs)\n",
    "#        x = batch['x'].to(torch.float32)\n",
    "#        x_lengths = batch['x_lengths']\n",
    "#        y_enc, y_dec, attn = model(x, x_lengths, n_timesteps=50)  # (B, 16, T) x 2 , (B,1,T0,T)\n",
    "#        print(\"y_enc.shape\", y_enc.shape, \"y_dec.shape\", y_dec.shape, \"attn.shape\", attn.shape)\n",
    "#        y_enc_14 = y_enc[:, reorder_feats, :].detach().cpu()\n",
    "#        y_dec_14 = y_dec[:, reorder_feats, :].detach().cpu()\n",
    "#        print(\"y_enc_14.shape\", y_enc_14.shape, \"y_dec_14.shape\", y_dec_14.shape)\n",
    "#        for j, (filepath, y_enc_j, y_dec_j) in enumerate(zip(batch_filepaths, y_enc_14, y_dec_14)):\n",
    "#            #save_path = save_dir / f\"{filepath[0].split('/')[-1][:-4]}.npy\"\n",
    "#            y_enc_dec_j = np.array([y_enc_j.numpy(),\n",
    "#                                    y_dec_j.numpy()]) # (2, 14, T)\n",
    "#            #print(f\"Saved {save_path}\")\n",
    "\n",
    "    #for filepaths in tqdm(filepaths_list, desc=\"Processing files\"):\n",
    "    #    phnm3_filepath = filepaths[1]\n",
    "    #    phnm_emb = dataset.get_phnm_emb(phnm3_filepath)\n",
    "    #    print(\"phnm_emb.shape\", phnm_emb.shape)\n",
    "    #    x = phnm_emb.to(torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "    #    x_lengths = torch.LongTensor([x.shape[-1]])\n",
    "    #    y_enc, y_dec, attn = model(x, x_lengths, n_timesteps=50)  # (1, n_feats, T) x 2 , (1,1,T0,T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089316ec",
   "metadata": {},
   "source": [
    "## arttts results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = DATA_DIR / \"LJSpeech-1.1\" / \"arttts_pred\" / version / grad_filename[:-3]\n",
    "ema_src_dir = DATA_DIR / \"LJSpeech-1.1\" / \"encoded_audio_en\" / \"emasrc\"\n",
    "\n",
    "reslist = sorted(list(results_dir.glob(\"*.npy\")))\n",
    "print(\"Files in reslist\", len(reslist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8302c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pitch_channel(art: np.ndarray, pitch_idx=12) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize the pitch channel to have zero mean and unit variance.\n",
    "    must be called after reordering the features.\n",
    "    \"\"\"\n",
    "    std = np.std(art[:, pitch_idx])\n",
    "    if std > 0:\n",
    "        art[:, pitch_idx] = (\n",
    "            art[:, pitch_idx] - np.mean(art[:, pitch_idx])\n",
    "        ) / np.std(art[:, pitch_idx])\n",
    "    else:\n",
    "        print(\"Zero variance in pitch channel. Centering to zero mean.\")\n",
    "        art[:, pitch_idx] = art[:, pitch_idx] - np.mean(\n",
    "            art[:, pitch_idx]\n",
    "        )\n",
    "    return art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c5e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = reslist[1]\n",
    "art_res = np.load(fp)\n",
    "print(\"art_res.shape\", art_res.shape)\n",
    "y_enc_14 = art_res[0].T  # (T, 14)\n",
    "y_dec_14 = art_res[1].T  # (T, 14)\n",
    "print(\"y_enc_14.shape\", y_enc_14.shape, \"y_dec_14.shape\", y_dec_14.shape)\n",
    "y_gt_ = np.load(ema_src_dir / fp.name)[:,:14]\n",
    "y_gt = normalize_pitch_channel(y_gt_, pitch_idx=12)\n",
    "print(\"y_gt.shape\", y_gt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from metrics import signals_from_path, normalized_dtw_score\n",
    "import numpy as np\n",
    "from utils import plot_art_14, plot_tensor\n",
    "\n",
    "fig1, im_data = plot_art_14([y_gt.T], title = \"y_gt\",)\n",
    "fig2, im_data = plot_art_14([y_enc_14.T], title = \"y_enc_14\",)\n",
    "fig3, im_data = plot_art_14([y_dec_14.T], title = \"y_dec_14\",)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 10))\n",
    "\n",
    "axes[0].imshow(fig1.canvas.renderer.buffer_rgba())\n",
    "axes[1].imshow(fig2.canvas.renderer.buffer_rgba())\n",
    "axes[2].imshow(fig3.canvas.renderer.buffer_rgba())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "art_feats = np.array([y_enc_14.T, y_dec_14.T])\n",
    "\n",
    "fig, im_data = plot_art_14(art_feats, title=\"y_enc, y_dec\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8273e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, im_data = plot_art_14(np.array([y_gt.T]), title=\"y_gt\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea257458",
   "metadata": {},
   "source": [
    "### DTW on enc and dec articulatory features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_gt_enc, y_gt_enc_ada, y_enc_14_ada = normalized_dtw_score(y_gt, y_enc_14)\n",
    "dist_gt_dec, y_gt_dec_ada, y_dec_14_ada = normalized_dtw_score(y_gt, y_dec_14)\n",
    "\n",
    "print(\"dist_gt_enc\", dist_gt_enc, \"dist_gt_dec\", dist_gt_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0101b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, im_data = plot_art_14([y_gt_enc_ada.T,\n",
    "            y_enc_14_ada.T,],\n",
    "            title = \"y_gt vs y_enc\",)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644edc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, im_data = plot_art_14([y_gt_dec_ada.T,\n",
    "            y_dec_14_ada.T,],\n",
    "            title = \"y_gt vs y_dec\",)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feae194e",
   "metadata": {},
   "source": [
    "### DTW on smoothened articulatory features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_multivariate_signal(signal: np.ndarray, window_size: int = 5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Smooth a multivariate signal using a moving average.\n",
    "\n",
    "    Parameters:\n",
    "    - signal: numpy array of shape (T, d), where T is the number of timesteps and d is the number of features.\n",
    "    - window_size: size of the moving average window.\n",
    "\n",
    "    Returns:\n",
    "    - smoothed_signal: numpy array of the same shape as input.\n",
    "    \"\"\"\n",
    "    kernel = np.ones(window_size) / window_size\n",
    "    smoothed_signal = np.apply_along_axis(\n",
    "        lambda x: np.convolve(x, kernel, mode='same'), axis=0, arr=signal\n",
    "    )\n",
    "    return smoothed_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d785ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dec_14_smoothed = smooth_multivariate_signal(y_dec_14, window_size=3)\n",
    "dist_gt_dec, y_gt_dec_ada, y_dec_14_ada = normalized_dtw_score(y_gt, y_dec_14_smoothed)\n",
    "y_enc_14_smoothed = smooth_multivariate_signal(y_enc_14, window_size=3)\n",
    "dist_gt_enc, y_gt_enc_ada, y_enc_14_ada = normalized_dtw_score(y_gt, y_enc_14_smoothed)\n",
    "\n",
    "print(\"dist_gt_enc (smoothed)\", dist_gt_enc, \"dist_gt_dec (smoothed)\", dist_gt_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090591af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, im_data = plot_art_14([y_gt_enc_ada.T,\n",
    "            y_enc_14_ada.T,],\n",
    "            title = \"y_gt vs y_enc\",)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284afdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, im_data = plot_art_14([y_gt_dec_ada.T,\n",
    "            y_dec_14_ada.T,],\n",
    "            title = \"y_gt vs y_dec\",)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c465a394",
   "metadata": {},
   "source": [
    "## Normal dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ed317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import signals_from_path\n",
    "from tslearn.metrics import dtw_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec264d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_scores = []\n",
    "dec_scores = []\n",
    "\n",
    "for idx in range(10):\n",
    "    y_gt = data[idx][\"y_gt\"]\n",
    "    y_enc_14 = data[idx][\"y_enc\"]\n",
    "    y_dec_14 = data[idx][\"y_dec\"]\n",
    "    path_gt_enc, dist_gt_enc = dtw_path(y_gt, y_enc_14)\n",
    "    path_gt_dec, dist_gt_dec = dtw_path(y_gt, y_dec_14)\n",
    "    y_gt_enc_ada, y_enc_14_ada = signals_from_path(y_gt, y_enc_14, path_gt_enc)\n",
    "    y_gt_dec_ada, y_dec_14_ada = signals_from_path(y_gt, y_dec_14, path_gt_dec)\n",
    "    enc_scores.append(dist_gt_enc)\n",
    "    dec_scores.append(dist_gt_dec)\n",
    "\n",
    "plt.plot(enc_scores, label=\"y_enc\")\n",
    "plt.plot(dec_scores, label=\"y_dec\")\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.ylabel(\"DTW distance\")\n",
    "plt.title(\"DTW distance between GT and predicted features\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "y_gt = data[idx][\"y_gt\"]\n",
    "y_enc_14 = data[idx][\"y_enc\"]\n",
    "y_dec_14 = data[idx][\"y_dec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gt_enc, dist_gt_enc = dtw_path(y_gt, y_enc_14)\n",
    "path_gt_dec, dist_gt_dec = dtw_path(y_gt, y_dec_14)\n",
    "\n",
    "print(\"dist_gt_enc\", dist_gt_enc, \"dist_gt_dec\", dist_gt_dec)\n",
    "\n",
    "y_gt_enc_ada, y_enc_14_ada = signals_from_path(y_gt, y_enc_14, path_gt_enc)\n",
    "y_gt_dec_ada, y_dec_14_ada = signals_from_path(y_gt, y_dec_14, path_gt_dec)\n",
    "\n",
    "fid, ax = plt.subplots(1,2, figsize=(10, 3))\n",
    "ax[0].plot(y_gt_enc_ada[:,0], label=\"y_gt_ada\")\n",
    "ax[0].plot(y_enc_14_ada[:,0], label=\"y_enc_14_ada\")\n",
    "\n",
    "ax[1].plot(y_gt_dec_ada[:,0], label=\"y_gt_ada\")\n",
    "ax[1].plot(y_dec_14_ada[:,0], label=\"y_dec_14_ada\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a7a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_art_14(np.array([y_gt_enc_ada,\n",
    "                      y_enc_14_ada,]), title=\"y_gt_adapted, y_enc_14_adapted\")\n",
    "plot_art_14(np.array([y_gt_dec_ada,\n",
    "                      y_dec_14_ada,]), title=\"y_gt_adapted, y_dec_14_adapted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc7bf5",
   "metadata": {},
   "source": [
    "## Wavelet dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c564e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "from tslearn.metrics import dtw_path_from_metric\n",
    "\n",
    "\n",
    "def wavelet_dtw_path(s1: np.ndarray, s2: np.ndarray, wavelet: str = \"db4\") -> list[tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Compute the DTW path between two signals using wavelet transform.\n",
    "    \n",
    "    Parameters:\n",
    "        - s1: First signal (shape: [n_frames, n_features])\n",
    "        - s2: Second signal (shape: [n_frames, n_features])\n",
    "        - wavelet: Wavelet type to use for the transform\n",
    "    \n",
    "    Returns:\n",
    "        - path_s1_s2: List of tuples representing the DTW path\n",
    "                    (i, j) where i is the index in s1 and j in s2.\n",
    "        - distance_s1_s2: The DTW distance between the two signals\n",
    "    \"\"\"\n",
    "    # ----- Step 1: Create multivariate signals -----\n",
    "    X = s1.T\n",
    "    Y = s2.T\n",
    "\n",
    "    X = (X - X.mean(axis=1, keepdims=True)) / (X.std(axis=1, keepdims=True) + 1e-6)\n",
    "    Y = (Y - Y.mean(axis=1, keepdims=True)) / (Y.std(axis=1, keepdims=True) + 1e-6)\n",
    "\n",
    "    # ----- Step 2: Wavelet Approximation -----\n",
    "    def wavelet_multichannel_approx(data, wavelet=wavelet, level=0):\n",
    "        \"\"\"Apply wavelet decomposition per channel and return approximation.\"\"\"\n",
    "        return np.array([\n",
    "            pywt.wavedec(channel, wavelet, mode='constant', level=level)[0]\n",
    "            for channel in data\n",
    "        ])\n",
    "\n",
    "    X_approx = wavelet_multichannel_approx(np.diff(X, axis=1, n=0))\n",
    "    Y_approx = wavelet_multichannel_approx(np.diff(Y, axis=1, n=0))\n",
    "\n",
    "    # ----- Step 3: Reshape for DTW -----\n",
    "    # Transpose to shape: [n_timesteps, n_channels]\n",
    "    X_seq = X_approx.T\n",
    "    Y_seq = Y_approx.T\n",
    "\n",
    "    # ----- Step 4: Define multivariate distance function -----\n",
    "    def multivariate_dtw_distance(a, b):\n",
    "        return np.linalg.norm(a - b)\n",
    "\n",
    "    # Build custom cost matrix\n",
    "    n, m = X_seq.shape[0], Y_seq.shape[0]\n",
    "    cost = np.zeros((n, m))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            cost[i, j] = multivariate_dtw_distance(X_seq[i], Y_seq[j])\n",
    "    \n",
    "    # ----- Step 5: Compute DTW alignment path -----\n",
    "    accumulated_cost = np.zeros((n, m))\n",
    "    accumulated_cost[0, 0] = cost[0, 0]\n",
    "    for i in range(1, n):\n",
    "        accumulated_cost[i, 0] = cost[i, 0] + accumulated_cost[i-1, 0]\n",
    "    for j in range(1, m):\n",
    "        accumulated_cost[0, j] = cost[0, j] + accumulated_cost[0, j-1]\n",
    "    for i in range(1, n):\n",
    "        for j in range(1, m):\n",
    "            accumulated_cost[i, j] = cost[i, j] + min(\n",
    "                accumulated_cost[i-1, j],\n",
    "                accumulated_cost[i, j-1],\n",
    "                accumulated_cost[i-1, j-1]\n",
    "            )\n",
    "    path_s1_s2, distance_s1_s2 = dtw_path_from_metric(accumulated_cost, metric='precomputed',\n",
    "                                                        global_constraint=\"sakoe_chiba\", sakoe_chiba_radius=50)\n",
    "    return path_s1_s2, distance_s1_s2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.metrics import dtw_path\n",
    "\n",
    "sakoe_rad = 5  # Sakoe-Chiba radius for DTW\n",
    "\n",
    "# Perform DTW between y_enc_14 and y_dec_14\n",
    "path_enc_dec, distance_enc_dec = dtw_path(y_enc_14, y_dec_14, global_constraint=\"sakoe_chiba\", sakoe_chiba_radius=sakoe_rad)\n",
    "\n",
    "# Perform DTW between y_gt and y_dec_14\n",
    "path_gt_dec, distance_gt_dec = dtw_path(y_gt[:,:14], y_dec_14[:,:14], global_constraint=\"sakoe_chiba\", sakoe_chiba_radius=sakoe_rad)\n",
    "\n",
    "# Perform DTW between y_gt and y_enc_14\n",
    "path_gt_enc, distance_gt_enc = dtw_path(y_gt[:,:14], y_enc_14[:,:14], global_constraint=\"sakoe_chiba\", sakoe_chiba_radius=sakoe_rad)\n",
    "\n",
    "# Print the distances\n",
    "print(\"DTW distance (y_enc_14, y_dec_14):\", distance_enc_dec)\n",
    "print(\"DTW distance (y_gt, y_enc_14):\", distance_gt_enc)\n",
    "print(\"DTW distance (y_gt, y_dec_14):\", distance_gt_dec)\n",
    "# At first sight better score on enc than dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd52a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_enc_14_adapted = signal_from_path(y_enc_14, path_gt_enc)\n",
    "y_dec_14_adapted = signal_from_path(y_dec_14, path_gt_dec)\n",
    "\n",
    "# Verify the shapes\n",
    "print(\"y_enc_14_adapted shape:\", y_enc_14_adapted.shape)\n",
    "print(\"y_dec_14_adapted shape:\", y_dec_14_adapted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "art_feats = np.array([y_gt[[e[0] for e in path_gt_dec]],\n",
    "                      y_dec_14_adapted,])\n",
    "\n",
    "plot_art_14(art_feats, title=\"y_dec, y_gt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ab068",
   "metadata": {},
   "outputs": [],
   "source": [
    "art_feats = np.array([y_gt[[e[0] for e in path_gt_enc]],\n",
    "                      y_enc_14_adapted,])\n",
    "\n",
    "plot_art_14(art_feats, title=\"y_enc, y_gt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb6c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def gaussian_smooth_signal(signal, sigma=1):\n",
    "    \"\"\"\n",
    "    Smoothens the signal using a Gaussian kernel.\n",
    "\n",
    "    Parameters:\n",
    "    - signal: numpy array of shape (n_timesteps, n_channels)\n",
    "    - sigma: standard deviation for Gaussian kernel\n",
    "\n",
    "    Returns:\n",
    "    - smoothed_signal: numpy array of the same shape as input\n",
    "    \"\"\"\n",
    "    smoothed_signal = np.zeros_like(signal)\n",
    "    for i in range(signal.shape[1]):  # Iterate over channels\n",
    "        smoothed_signal[:, i] = gaussian_filter1d(signal[:, i], sigma=sigma)\n",
    "    return smoothed_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf7265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_signal(signal, window_size=5):\n",
    "    \"\"\"\n",
    "    Smoothens the signal using a moving average.\n",
    "\n",
    "    Parameters:\n",
    "    - signal: numpy array of shape (n_timesteps, n_channels)\n",
    "    - window_size: size of the moving average window\n",
    "\n",
    "    Returns:\n",
    "    - smoothed_signal: numpy array of the same shape as input\n",
    "    \"\"\"\n",
    "    smoothed_signal = np.zeros_like(signal)\n",
    "    for i in range(signal.shape[1]):  # Iterate over channels\n",
    "        smoothed_signal[:, i] = np.convolve(signal[:, i], \n",
    "                                            np.ones(window_size)/window_size, \n",
    "                                            mode='same')\n",
    "    return smoothed_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93665e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.metrics import dtw_path_from_metric\n",
    "\n",
    "eps = 4e-3\n",
    "n=1\n",
    "\n",
    "\n",
    "#normalize the signal\n",
    "x = (y_gt - y_gt.mean(axis=0)) / (y_gt.std(axis=0) + 1e-6)\n",
    "y = (y_dec_14 - y_dec_14.mean(axis=0)) / (y_dec_14.std(axis=0) + 1e-6)\n",
    "\n",
    "x = gaussian_smooth_signal(x, sigma=3) # + np.random.uniform(-eps, eps, (x.shape[0], 1))\n",
    "y = gaussian_smooth_signal(y, sigma=3) #+ np.random.uniform(-eps, eps, (y.shape[0], 1))\n",
    "\n",
    "x = np.diff(x, axis=0, n=n)[:,:14]\n",
    "y = np.diff(y, axis=0, n=n)[:,:14]\n",
    "\n",
    "#x *= local_smoothness_gradient(x, window=11)\n",
    "#y *= local_smoothness_gradient(y, window=11)\n",
    "#\n",
    "#x = np.sign(x) * (np.abs(x))\n",
    "#y = np.sign(y) * (np.abs(y))\n",
    "#\n",
    "#ord=2\n",
    "#distance_matrix = np.linalg.norm(x[:, None, :] - y[None, :, :], axis=2, ord=ord)\n",
    "\n",
    "#path_gt_enc, distance_gt_enc = dtw_path_from_metric(distance_matrix, metric='precomputed', global_constraint=\"itakura\", itakura_max_slope=1.3)\n",
    "#path_gt_dec, distance_gt_dec = dtw_path(x, y, global_constraint=\"sakoe_chiba\", sakoe_chiba_radius=10)\n",
    "path_gt_dec, distance_gt_dec = dtw_path_from_metric(x, y, metric='cosine', global_constraint=\"sakoe_chiba\", sakoe_chiba_radius=10)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10, 5))\n",
    "\n",
    "ax[0].plot(x[:, 0], label=\"x\")\n",
    "ax[0].plot(y[:, 0], label=\"y_dec_14\")\n",
    "\n",
    "y_gt_adapted = x[[e[0] for e in path_gt_dec]]\n",
    "y_dec_14_adapted = signal_from_path(y, path_gt_dec)\n",
    "ax[1].plot(y_gt_adapted[:,0], label='y_gt')\n",
    "ax[1].plot(y_dec_14_adapted[:, 0], label='y_dec_14_adapted')\n",
    "print(\"DTW distance (y_gt, y_dec_14):\", distance_gt_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9e3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dec_14_adapted = signal_from_path(y_dec_14, path_gt_dec)\n",
    "\n",
    "y_gt_adapted = y_gt[[e[0] for e in path_gt_dec]]\n",
    "art_feats = np.array([y_gt_adapted,\n",
    "                      y_dec_14_adapted,])\n",
    "\n",
    "plot_art_14(art_feats, title=\"y_enc, y_enc, y_gt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
