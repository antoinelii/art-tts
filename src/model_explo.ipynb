{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9285a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import (LJLISTS_DIR, LOGS_DIR, \n",
    "                  WAVS_DIR, EMASRC_DIR, SPK_EMB_DIR,\n",
    "                  ENCODED_AUDIO_EN_DIR) \n",
    "\n",
    "version = \"v0_es_ema_200\"\n",
    "train_info_dir = LOGS_DIR / version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import GradTTS\n",
    "from configs import params_v0\n",
    "\n",
    "model = GradTTS(\n",
    "        params_v0.n_ipa_feats,\n",
    "        params_v0.n_spks,\n",
    "        None if params_v0.n_spks == 1 else params_v0.spk_emb_dim, #spk_emb_dim\n",
    "        params_v0.n_enc_channels,\n",
    "        params_v0.filter_channels,\n",
    "        params_v0.filter_channels_dp,\n",
    "        params_v0.n_heads,\n",
    "        params_v0.n_enc_layers,\n",
    "        params_v0.enc_kernel,\n",
    "        params_v0.enc_dropout,\n",
    "        params_v0.window_size,\n",
    "        params_v0.n_feats,\n",
    "        params_v0.dec_dim,\n",
    "        params_v0.beta_min,\n",
    "        params_v0.beta_max,\n",
    "        params_v0.pe_scale,\n",
    "    )\n",
    "\n",
    "grad_filename = 'grad_10.pt'\n",
    "ckpt_state_dict = torch.load(train_info_dir / grad_filename,\n",
    "                  map_location=torch.device('cpu'))\n",
    "model.load_state_dict(ckpt_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54fd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import TextArticDataset, TextArticBatchCollate\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_dataset = TextArticDataset(\n",
    "        LJLISTS_DIR / 'train_v0.txt',\n",
    "        params_v0.cmudict_path,\n",
    "        params_v0.add_blank,\n",
    "        wavs_dir=WAVS_DIR,\n",
    "        artic_dir=ENCODED_AUDIO_EN_DIR,\n",
    "        load_coder=False,\n",
    "        shuffle=False,\n",
    "        merge_diphtongues=True,\n",
    "    )\n",
    "valid_dataset = TextArticDataset(\n",
    "        LJLISTS_DIR / 'valid_v0.txt',\n",
    "        params_v0.cmudict_path,\n",
    "        params_v0.add_blank,\n",
    "        wavs_dir=WAVS_DIR,\n",
    "        artic_dir=ENCODED_AUDIO_EN_DIR,\n",
    "        load_coder=False,\n",
    "        shuffle=False,\n",
    "        merge_diphtongues=True,\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataset.filepaths_and_text = train_dataset.filepaths_and_text[:10]\n",
    "valid_dataset.filepaths_and_text = valid_dataset.filepaths_and_text[:10]\n",
    "print(\"train_size\", len(train_dataset), \"valid_size\", len(valid_dataset))\n",
    "\n",
    "batch_collate = TextArticBatchCollate()\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=batch_collate,\n",
    "    drop_last=True,\n",
    "    shuffle=False,\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=batch_collate,\n",
    "    drop_last=True,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dbf64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.params_v0 import reorder_feats\n",
    "\n",
    "N = len(valid_dataset)\n",
    "#N=1\n",
    "data = {}\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(N):\n",
    "        item = batch_collate([valid_dataset[i]])\n",
    "        x = item[\"x\"].to(torch.float32)\n",
    "        x_lengths = torch.LongTensor([x.shape[-1]])\n",
    "        y_enc, y_dec, attn = model(x, x_lengths, n_timesteps=50)\n",
    "        y_enc_14 = y_enc[0,reorder_feats,:].T.cpu().numpy()\n",
    "        y_dec_14 = y_dec[0,reorder_feats,:].T.cpu().numpy()\n",
    "        y_gt = item[\"y\"][0,reorder_feats,:].T.cpu().numpy()\n",
    "        data[i] = {\n",
    "            \"x\": x[0].cpu().numpy(),\n",
    "            \"y_enc\": y_enc_14,\n",
    "            \"y_dec\": y_dec_14,\n",
    "            \"y_gt\": y_gt,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc387f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import plot_art_14\n",
    "\n",
    "art_feats = np.array([y_enc_14, y_dec_14])\n",
    "\n",
    "plot_art_14(art_feats, title=\"y_enc, y_dec\")\n",
    "plot_art_14(np.array([y_gt]), title=\"y_gt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f64b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][\"y_dec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcd25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a\n",
    "\n",
    "truc = plot_art_14(np.vstack([data[0][\"y_dec\"][None,:,:],\n",
    "                             data[0][\"y_enc\"][None, :,:]]), title=\"y_dec\")\n",
    "plt.imshow(truc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef87cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "truc = plot_art_14([data[0][\"y_dec\"].T,\n",
    "                  data[0][\"y_enc\"].T,\n",
    "                  ],\n",
    "                  title_prefix=\"y_dec, y_enc\",\n",
    "                figsize=(10, 5))\n",
    "#plt.imshow(truc)\n",
    "plt.imshow(truc[:,:,[1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b15a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [True, False, False]\n",
    "if any(a):\n",
    "    print(\"any true\")\n",
    "else:\n",
    "    print(\"all false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7efbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, truc = plot_art_14([data[0][\"y_dec\"].T,\n",
    "                  data[0][\"y_enc\"].T,\n",
    "                  ],\n",
    "                  title_prefix=\"y_dec, y_enc\",\n",
    "                figsize=(8, 5))\n",
    "#plt.imshow(truc)\n",
    "#plt.imshow(truc[:,:,[1,2,3]])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c465a394",
   "metadata": {},
   "source": [
    "## Normal dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ed317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import signals_from_path\n",
    "from tslearn.metrics import dtw_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec264d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_scores = []\n",
    "dec_scores = []\n",
    "\n",
    "for idx in range(10):\n",
    "    y_gt = data[idx][\"y_gt\"]\n",
    "    y_enc_14 = data[idx][\"y_enc\"]\n",
    "    y_dec_14 = data[idx][\"y_dec\"]\n",
    "    path_gt_enc, dist_gt_enc = dtw_path(y_gt, y_enc_14)\n",
    "    path_gt_dec, dist_gt_dec = dtw_path(y_gt, y_dec_14)\n",
    "    y_gt_enc_ada, y_enc_14_ada = signals_from_path(y_gt, y_enc_14, path_gt_enc)\n",
    "    y_gt_dec_ada, y_dec_14_ada = signals_from_path(y_gt, y_dec_14, path_gt_dec)\n",
    "    enc_scores.append(dist_gt_enc)\n",
    "    dec_scores.append(dist_gt_dec)\n",
    "\n",
    "plt.plot(enc_scores, label=\"y_enc\")\n",
    "plt.plot(dec_scores, label=\"y_dec\")\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.ylabel(\"DTW distance\")\n",
    "plt.title(\"DTW distance between GT and predicted features\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "y_gt = data[idx][\"y_gt\"]\n",
    "y_enc_14 = data[idx][\"y_enc\"]\n",
    "y_dec_14 = data[idx][\"y_dec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gt_enc, dist_gt_enc = dtw_path(y_gt, y_enc_14)\n",
    "path_gt_dec, dist_gt_dec = dtw_path(y_gt, y_dec_14)\n",
    "\n",
    "print(\"dist_gt_enc\", dist_gt_enc, \"dist_gt_dec\", dist_gt_dec)\n",
    "\n",
    "y_gt_enc_ada, y_enc_14_ada = signals_from_path(y_gt, y_enc_14, path_gt_enc)\n",
    "y_gt_dec_ada, y_dec_14_ada = signals_from_path(y_gt, y_dec_14, path_gt_dec)\n",
    "\n",
    "fid, ax = plt.subplots(1,2, figsize=(10, 3))\n",
    "ax[0].plot(y_gt_enc_ada[:,0], label=\"y_gt_ada\")\n",
    "ax[0].plot(y_enc_14_ada[:,0], label=\"y_enc_14_ada\")\n",
    "\n",
    "ax[1].plot(y_gt_dec_ada[:,0], label=\"y_gt_ada\")\n",
    "ax[1].plot(y_dec_14_ada[:,0], label=\"y_dec_14_ada\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a7a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_art_14(np.array([y_gt_enc_ada,\n",
    "                      y_enc_14_ada,]), title=\"y_gt_adapted, y_enc_14_adapted\")\n",
    "plot_art_14(np.array([y_gt_dec_ada,\n",
    "                      y_dec_14_ada,]), title=\"y_gt_adapted, y_dec_14_adapted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc7bf5",
   "metadata": {},
   "source": [
    "## Wavelet dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c564e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "from tslearn.metrics import dtw_path_from_metric\n",
    "\n",
    "\n",
    "def wavelet_dtw_path(s1: np.ndarray, s2: np.ndarray, wavelet: str = \"db4\") -> list[tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Compute the DTW path between two signals using wavelet transform.\n",
    "    \n",
    "    Parameters:\n",
    "        - s1: First signal (shape: [n_frames, n_features])\n",
    "        - s2: Second signal (shape: [n_frames, n_features])\n",
    "        - wavelet: Wavelet type to use for the transform\n",
    "    \n",
    "    Returns:\n",
    "        - path_s1_s2: List of tuples representing the DTW path\n",
    "                    (i, j) where i is the index in s1 and j in s2.\n",
    "        - distance_s1_s2: The DTW distance between the two signals\n",
    "    \"\"\"\n",
    "    # ----- Step 1: Create multivariate signals -----\n",
    "    X = s1.T\n",
    "    Y = s2.T\n",
    "\n",
    "    X = (X - X.mean(axis=1, keepdims=True)) / (X.std(axis=1, keepdims=True) + 1e-6)\n",
    "    Y = (Y - Y.mean(axis=1, keepdims=True)) / (Y.std(axis=1, keepdims=True) + 1e-6)\n",
    "\n",
    "    # ----- Step 2: Wavelet Approximation -----\n",
    "    def wavelet_multichannel_approx(data, wavelet=wavelet, level=0):\n",
    "        \"\"\"Apply wavelet decomposition per channel and return approximation.\"\"\"\n",
    "        return np.array([\n",
    "            pywt.wavedec(channel, wavelet, mode='constant', level=level)[0]\n",
    "            for channel in data\n",
    "        ])\n",
    "\n",
    "    X_approx = wavelet_multichannel_approx(np.diff(X, axis=1, n=0))\n",
    "    Y_approx = wavelet_multichannel_approx(np.diff(Y, axis=1, n=0))\n",
    "\n",
    "    # ----- Step 3: Reshape for DTW -----\n",
    "    # Transpose to shape: [n_timesteps, n_channels]\n",
    "    X_seq = X_approx.T\n",
    "    Y_seq = Y_approx.T\n",
    "\n",
    "    # ----- Step 4: Define multivariate distance function -----\n",
    "    def multivariate_dtw_distance(a, b):\n",
    "        return np.linalg.norm(a - b)\n",
    "\n",
    "    # Build custom cost matrix\n",
    "    n, m = X_seq.shape[0], Y_seq.shape[0]\n",
    "    cost = np.zeros((n, m))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            cost[i, j] = multivariate_dtw_distance(X_seq[i], Y_seq[j])\n",
    "    \n",
    "    # ----- Step 5: Compute DTW alignment path -----\n",
    "    accumulated_cost = np.zeros((n, m))\n",
    "    accumulated_cost[0, 0] = cost[0, 0]\n",
    "    for i in range(1, n):\n",
    "        accumulated_cost[i, 0] = cost[i, 0] + accumulated_cost[i-1, 0]\n",
    "    for j in range(1, m):\n",
    "        accumulated_cost[0, j] = cost[0, j] + accumulated_cost[0, j-1]\n",
    "    for i in range(1, n):\n",
    "        for j in range(1, m):\n",
    "            accumulated_cost[i, j] = cost[i, j] + min(\n",
    "                accumulated_cost[i-1, j],\n",
    "                accumulated_cost[i, j-1],\n",
    "                accumulated_cost[i-1, j-1]\n",
    "            )\n",
    "    path_s1_s2, distance_s1_s2 = dtw_path_from_metric(accumulated_cost, metric='precomputed',\n",
    "                                                        global_constraint=\"sakoe_chiba\", sakoe_chiba_radius=50)\n",
    "    return path_s1_s2, distance_s1_s2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.metrics import dtw_path\n",
    "\n",
    "sakoe_rad = 5  # Sakoe-Chiba radius for DTW\n",
    "\n",
    "# Perform DTW between y_enc_14 and y_dec_14\n",
    "path_enc_dec, distance_enc_dec = dtw_path(y_enc_14, y_dec_14, global_constraint=\"sakoe_chiba\", sakoe_chiba_radius=sakoe_rad)\n",
    "\n",
    "# Perform DTW between y_gt and y_dec_14\n",
    "path_gt_dec, distance_gt_dec = dtw_path(y_gt[:,:14], y_dec_14[:,:14], global_constraint=\"sakoe_chiba\", sakoe_chiba_radius=sakoe_rad)\n",
    "\n",
    "# Perform DTW between y_gt and y_enc_14\n",
    "path_gt_enc, distance_gt_enc = dtw_path(y_gt[:,:14], y_enc_14[:,:14], global_constraint=\"sakoe_chiba\", sakoe_chiba_radius=sakoe_rad)\n",
    "\n",
    "# Print the distances\n",
    "print(\"DTW distance (y_enc_14, y_dec_14):\", distance_enc_dec)\n",
    "print(\"DTW distance (y_gt, y_enc_14):\", distance_gt_enc)\n",
    "print(\"DTW distance (y_gt, y_dec_14):\", distance_gt_dec)\n",
    "# At first sight better score on enc than dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd52a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_enc_14_adapted = signal_from_path(y_enc_14, path_gt_enc)\n",
    "y_dec_14_adapted = signal_from_path(y_dec_14, path_gt_dec)\n",
    "\n",
    "# Verify the shapes\n",
    "print(\"y_enc_14_adapted shape:\", y_enc_14_adapted.shape)\n",
    "print(\"y_dec_14_adapted shape:\", y_dec_14_adapted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "art_feats = np.array([y_gt[[e[0] for e in path_gt_dec]],\n",
    "                      y_dec_14_adapted,])\n",
    "\n",
    "plot_art_14(art_feats, title=\"y_dec, y_gt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ab068",
   "metadata": {},
   "outputs": [],
   "source": [
    "art_feats = np.array([y_gt[[e[0] for e in path_gt_enc]],\n",
    "                      y_enc_14_adapted,])\n",
    "\n",
    "plot_art_14(art_feats, title=\"y_enc, y_gt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb6c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def gaussian_smooth_signal(signal, sigma=1):\n",
    "    \"\"\"\n",
    "    Smoothens the signal using a Gaussian kernel.\n",
    "\n",
    "    Parameters:\n",
    "    - signal: numpy array of shape (n_timesteps, n_channels)\n",
    "    - sigma: standard deviation for Gaussian kernel\n",
    "\n",
    "    Returns:\n",
    "    - smoothed_signal: numpy array of the same shape as input\n",
    "    \"\"\"\n",
    "    smoothed_signal = np.zeros_like(signal)\n",
    "    for i in range(signal.shape[1]):  # Iterate over channels\n",
    "        smoothed_signal[:, i] = gaussian_filter1d(signal[:, i], sigma=sigma)\n",
    "    return smoothed_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf7265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_signal(signal, window_size=5):\n",
    "    \"\"\"\n",
    "    Smoothens the signal using a moving average.\n",
    "\n",
    "    Parameters:\n",
    "    - signal: numpy array of shape (n_timesteps, n_channels)\n",
    "    - window_size: size of the moving average window\n",
    "\n",
    "    Returns:\n",
    "    - smoothed_signal: numpy array of the same shape as input\n",
    "    \"\"\"\n",
    "    smoothed_signal = np.zeros_like(signal)\n",
    "    for i in range(signal.shape[1]):  # Iterate over channels\n",
    "        smoothed_signal[:, i] = np.convolve(signal[:, i], \n",
    "                                            np.ones(window_size)/window_size, \n",
    "                                            mode='same')\n",
    "    return smoothed_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93665e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.metrics import dtw_path_from_metric\n",
    "\n",
    "eps = 4e-3\n",
    "n=1\n",
    "\n",
    "\n",
    "#normalize the signal\n",
    "x = (y_gt - y_gt.mean(axis=0)) / (y_gt.std(axis=0) + 1e-6)\n",
    "y = (y_dec_14 - y_dec_14.mean(axis=0)) / (y_dec_14.std(axis=0) + 1e-6)\n",
    "\n",
    "x = gaussian_smooth_signal(x, sigma=3) # + np.random.uniform(-eps, eps, (x.shape[0], 1))\n",
    "y = gaussian_smooth_signal(y, sigma=3) #+ np.random.uniform(-eps, eps, (y.shape[0], 1))\n",
    "\n",
    "x = np.diff(x, axis=0, n=n)[:,:14]\n",
    "y = np.diff(y, axis=0, n=n)[:,:14]\n",
    "\n",
    "#x *= local_smoothness_gradient(x, window=11)\n",
    "#y *= local_smoothness_gradient(y, window=11)\n",
    "#\n",
    "#x = np.sign(x) * (np.abs(x))\n",
    "#y = np.sign(y) * (np.abs(y))\n",
    "#\n",
    "#ord=2\n",
    "#distance_matrix = np.linalg.norm(x[:, None, :] - y[None, :, :], axis=2, ord=ord)\n",
    "\n",
    "#path_gt_enc, distance_gt_enc = dtw_path_from_metric(distance_matrix, metric='precomputed', global_constraint=\"itakura\", itakura_max_slope=1.3)\n",
    "#path_gt_dec, distance_gt_dec = dtw_path(x, y, global_constraint=\"sakoe_chiba\", sakoe_chiba_radius=10)\n",
    "path_gt_dec, distance_gt_dec = dtw_path_from_metric(x, y, metric='cosine', global_constraint=\"sakoe_chiba\", sakoe_chiba_radius=10)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10, 5))\n",
    "\n",
    "ax[0].plot(x[:, 0], label=\"x\")\n",
    "ax[0].plot(y[:, 0], label=\"y_dec_14\")\n",
    "\n",
    "y_gt_adapted = x[[e[0] for e in path_gt_dec]]\n",
    "y_dec_14_adapted = signal_from_path(y, path_gt_dec)\n",
    "ax[1].plot(y_gt_adapted[:,0], label='y_gt')\n",
    "ax[1].plot(y_dec_14_adapted[:, 0], label='y_dec_14_adapted')\n",
    "print(\"DTW distance (y_gt, y_dec_14):\", distance_gt_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9e3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dec_14_adapted = signal_from_path(y_dec_14, path_gt_dec)\n",
    "\n",
    "y_gt_adapted = y_gt[[e[0] for e in path_gt_dec]]\n",
    "art_feats = np.array([y_gt_adapted,\n",
    "                      y_dec_14_adapted,])\n",
    "\n",
    "plot_art_14(art_feats, title=\"y_enc, y_enc, y_gt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
