{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9285a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import DATA_DIR, LJLISTS_DIR, LOGS_DIR, FILELISTS_DIR\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from text import cmudict\n",
    "from utils import parse_filelist, intersperse\n",
    "\n",
    "from text.converters import ipa_to_ternary, text_to_ipa, traits_list\n",
    "from panphon import FeatureTable\n",
    "\n",
    "ft = FeatureTable()\n",
    "\n",
    "cmudict_path = \"resources/cmu_dictionary\"\n",
    "dictionary_cmu = cmudict.CMUDict(cmudict_path)\n",
    "cleaner_names = [\"english_cleaners_v2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff82c3e",
   "metadata": {},
   "source": [
    "## MNGU0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4bc0556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mngu0_dir = DATA_DIR / 'MNGU0' / \"src_data\" / \"s1\" / \"phone_labels\"\n",
    "\n",
    "utt_files = sorted(list(mngu0_dir.glob('*.utt')))\n",
    "lab_files = sorted(list(mngu0_dir.glob('*.lab')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ab204819",
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_file = utt_files[0]  # Example utt file\n",
    "lab_file = lab_files[0]  # Example lab file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c7ecc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: If you want to regulate noise, regulate noise.\n",
      "IPA Phones: [(0.   , 0.488, '.') (0.488, 0.554, 'ɪ') (0.554, 0.634, 'f')\n",
      " (0.634, 0.676, 'j') (0.676, 0.708, 'uː') (0.708, 0.78 , 'w')\n",
      " (0.78 , 0.842, 'ɒ') (0.842, 0.896, 'n') (0.896, 0.914, 't')\n",
      " (0.914, 0.974, 't') (0.974, 1.004, 'uː') (1.004, 1.104, 'ɹ')\n",
      " (1.104, 1.148, 'ɛ') (1.148, 1.218, 'ɡ') (1.218, 1.238, 'j')\n",
      " (1.238, 1.282, 'uː') (1.282, 1.35 , 'l') (1.35 , 1.458, 'ɛɪ')\n",
      " (1.458, 1.518, 't') (1.518, 1.586, 'n') (1.586, 1.88 , 'ɔɪ')\n",
      " (1.88 , 2.028, 'z') (2.028, 2.174, '.') (2.174, 2.23 , 'ɹ')\n",
      " (2.23 , 2.25 , 'ɛ') (2.25 , 2.324, 'ɡ') (2.324, 2.356, 'j')\n",
      " (2.356, 2.394, 'uː') (2.394, 2.462, 'l') (2.462, 2.58 , 'ɛɪ')\n",
      " (2.58 , 2.62 , 't') (2.62 , 2.712, 'n') (2.712, 2.976, 'ɔɪ')\n",
      " (2.976, 3.142, 'z') (3.142, 3.612, '.')]\n",
      "IPA Phones: 35\n",
      "Ternary Phones: torch.Size([25, 35])\n"
     ]
    }
   ],
   "source": [
    "from utils_dataset.mngu0 import mngu02ipa, get_mngu0_sentence, get_mngu0_phnm3\n",
    "\n",
    "sentence = get_mngu0_sentence(utt_file)\n",
    "ipa_phnm3 = get_mngu0_phnm3(lab_file) # norm\n",
    "ipawords_list = ['%'.join([elem[2] for elem in ipa_phnm3])]\n",
    "ternary_emb_phnm = ipa_to_ternary(ipawords_list, merge_diphtongues=True)\n",
    "ternary_emb_phnm = torch.FloatTensor(ternary_emb_phnm).T \n",
    "print(f\"Sentence: {sentence}\")\n",
    "print(f\"IPA Phones: {ipa_phnm3}\")\n",
    "print(f\"IPA Phones: {len(ipa_phnm3)}\")\n",
    "print(f\"Ternary Phones: {ternary_emb_phnm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d2c53b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 34])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = sentence\n",
    "add_blank = False  # Whether to add a blank token between IPA symbols\n",
    "merge_diphtongues = True  # Whether to merge diphthongs into single symbols\n",
    "\n",
    "ipawords_list = text_to_ipa(\n",
    "    text,\n",
    "    dictionary=dictionary_cmu,\n",
    "    cleaner_names=[\"english_cleaners_v2\"],\n",
    "    remove_punctuation=False,\n",
    ")\n",
    "if add_blank:\n",
    "    ipawords_list = intersperse(ipawords_list, \" \")\n",
    "ternary_emb = ipa_to_ternary(\n",
    "    ipawords_list, merge_diphtongues=merge_diphtongues\n",
    ")\n",
    "ternary_emb = torch.FloatTensor(ternary_emb).T  # shape: (n_ipa_feats, seq_len)\n",
    "ternary_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36d923fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in mngu02ipa.items():\n",
    "    emb = ipa_to_ternary([v], merge_diphtongues=True)\n",
    "    if emb.shape[0] != 1:\n",
    "        print(f\"emb shape: {emb.shape}\")\n",
    "        print(f\"Invalid IPA: {v} for MNGU0 phone {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc0980e",
   "metadata": {},
   "source": [
    "## Mocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bf4225a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This was easy for us.\n",
      "Phonemes: [(0.  , 0.87   , '.') (0.87, 0.91   , 'd') (0.91, 1.     , 'ɪ')\n",
      " (1.  , 1.15   , 's') (1.15, 1.22   , 'w') (1.22, 1.26   , 'ə')\n",
      " (1.26, 1.37   , 'z') (1.37, 1.5    , 'iː') (1.5 , 1.6    , 'z')\n",
      " (1.6 , 1.67   , 'i') (1.67, 1.83   , 'f') (1.83, 1.92   , 'ə')\n",
      " (1.92, 2.09   , 'ə') (2.09, 2.34   , 's') (2.34, 2.96875, '.')]\n"
     ]
    }
   ],
   "source": [
    "mocha_dir = DATA_DIR / 'mocha_timit'\n",
    "mocha_trans_files = sorted(list(mocha_dir.glob('*.trans')))\n",
    "mocha_phnm_files = sorted(list(mocha_dir.glob('*.phnm')))\n",
    "\n",
    "trans_file = mocha_trans_files[0]  # Example trans file\n",
    "phnm_file = mocha_phnm_files[0]  # Example phnm file\n",
    "\n",
    "from utils_dataset.mocha import get_mocha_sentence, get_mocha_phnm3\n",
    "\n",
    "sentence = get_mocha_sentence(trans_file)\n",
    "ipa_phnm3 = get_mocha_phnm3(phnm_file)\n",
    "print(f\"Sentence: {sentence}\")\n",
    "print(f\"Phonemes: {ipa_phnm3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6c6fe55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This was easy for us.\n",
      "IPA Phones: [(0.  , 0.87   , '.') (0.87, 0.91   , 'd') (0.91, 1.     , 'ɪ')\n",
      " (1.  , 1.15   , 's') (1.15, 1.22   , 'w') (1.22, 1.26   , 'ə')\n",
      " (1.26, 1.37   , 'z') (1.37, 1.5    , 'iː') (1.5 , 1.6    , 'z')\n",
      " (1.6 , 1.67   , 'i') (1.67, 1.83   , 'f') (1.83, 1.92   , 'ə')\n",
      " (1.92, 2.09   , 'ə') (2.09, 2.34   , 's') (2.34, 2.96875, '.')]\n",
      "IPA Phones: 15\n",
      "Ternary Phones: torch.Size([25, 15])\n"
     ]
    }
   ],
   "source": [
    "ipawords_list = ['%'.join([elem[2] for elem in ipa_phnm3])]\n",
    "ternary_emb_phnm = ipa_to_ternary(ipawords_list, merge_diphtongues=True)\n",
    "ternary_emb_phnm = torch.FloatTensor(ternary_emb_phnm).T \n",
    "print(f\"Sentence: {sentence}\")\n",
    "print(f\"IPA Phones: {ipa_phnm3}\")\n",
    "print(f\"IPA Phones: {len(ipa_phnm3)}\")\n",
    "print(f\"Ternary Phones: {ternary_emb_phnm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "31a709e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 15])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = sentence\n",
    "add_blank = False  # Whether to add a blank token between IPA symbols\n",
    "merge_diphtongues = True  # Whether to merge diphthongs into single symbols\n",
    "\n",
    "ipawords_list = text_to_ipa(\n",
    "    text,\n",
    "    dictionary=dictionary_cmu,\n",
    "    cleaner_names=[\"english_cleaners_v2\"],\n",
    "    remove_punctuation=False,\n",
    ")\n",
    "if add_blank:\n",
    "    ipawords_list = intersperse(ipawords_list, \" \")\n",
    "ternary_emb = ipa_to_ternary(\n",
    "    ipawords_list, merge_diphtongues=merge_diphtongues\n",
    ")\n",
    "ternary_emb = torch.FloatTensor(ternary_emb).T  # shape: (n_ipa_feats, seq_len)\n",
    "ternary_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5c8c575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonems = set()\n",
    "mocha_phnm_files = sorted(list(mocha_dir.glob('*arttts/*/phnm3/*_phnm3.npy')))\n",
    "for phnm_file in mocha_phnm_files:\n",
    "    #phnm3 = get_mocha_phnm3(phnm_file)\n",
    "    phnm3 = np.load(phnm_file)\n",
    "    for s, e, phone in phnm3:\n",
    "        phonems.add(phone)\n",
    "        if phone != \".\" and not ft.validate_word(phone):\n",
    "            print(f\"Invalid IPA: {phone} in file {phnm_file.name}\")\n",
    "        #emb = ipa_to_ternary([phone], merge_diphtongues=True)\n",
    "        #if emb.shape[0] != 1:\n",
    "        #    print(f\"emb shape: {emb.shape}\")\n",
    "        #    print(f\"Invalid IPA: {phone} in file {phnm_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a381930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in phonems:\n",
    "    emb = ipa_to_ternary([v], merge_diphtongues=True)\n",
    "    if emb.shape[0] != 1:\n",
    "        print(f\"emb shape: {emb.shape}\")\n",
    "        print(f\"Invalid IPA: {v} for MNGU0 phone {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae5f4af",
   "metadata": {},
   "source": [
    "## MSPKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eaf1d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_dataset.mspka import get_mspka_sentence, get_mspka_phnm3, mspka2ipa\n",
    "\n",
    "mspka_dir = DATA_DIR / 'MSPKA_EMA_ita'\n",
    "mspka_lab_files = sorted(list(mspka_dir.glob('*.lab')))\n",
    "mspka_sent_files = sorted(list(mspka_dir.glob('list_sentences')))\n",
    "\n",
    "lab_file = mspka_lab_files[0]  # Example lab file\n",
    "sent_file = mspka_sent_files[0]  # Example phnm file\n",
    "\n",
    "sentence = get_mspka_sentence(sent_file)\n",
    "ipa_phnm3 = get_mspka_phnm3(lab_file)\n",
    "\n",
    "#with open(sent_file, 'r', encoding='utf-8') as f:\n",
    "#    sentence = f.read().strip()\n",
    "#print(f\"Sentence from file: {sentence}\")\n",
    "\n",
    "#mspka_phnms = set()\n",
    "#\n",
    "#for lab_file in mspka_lab_files:\n",
    "#    sent, phnm3 = get_mspka_sentence_phnm3(lab_file)\n",
    "#    for s, e, phone in phnm3:\n",
    "#        mspka_phnms.add(phone)\n",
    "#mspka_phnms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02fe165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab_file in mspka_lab_files:\n",
    "    sentence = get_mspka_sentence(lab_file)[0]\n",
    "    phnm3 = get_mspka_phnm3(lab_file)\n",
    "    for s, e, phone in phnm3:\n",
    "        if phone != \".\" and not ft.validate_word(phone):\n",
    "            print(f\"Invalid IPA: {phone} in file {lab_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5027465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: ('erano concesse dal comune che poi furono tolte', [])\n",
      "IPA Phones: [(0.  , 0.35, '.') (0.35, 0.54, 'ɛ') (0.54, 0.59, 'ɾ') (0.59, 0.65, 'a')\n",
      " (0.65, 0.7 , 'n') (0.7 , 0.79, 'o') (0.79, 0.85, 'k') (0.85, 0.89, 'o')\n",
      " (0.89, 0.98, 'n') (0.98, 1.07, 't͡ʃ') (1.07, 1.15, 'ɛ')\n",
      " (1.15, 1.28, 'sː') (1.28, 1.32, 'e') (1.32, 1.37, 'd') (1.37, 1.42, 'a')\n",
      " (1.42, 1.48, 'l') (1.48, 1.56, 'k') (1.56, 1.62, 'o') (1.62, 1.75, 'm')\n",
      " (1.75, 1.89, 'u') (1.89, 1.94, 'n') (1.94, 2.06, 'e') (2.06, 2.4 , 'k')\n",
      " (2.4 , 2.51, 'e') (2.51, 2.58, 'p') (2.58, 2.76, 'ɔ') (2.76, 2.84, 'i')\n",
      " (2.84, 2.97, 'f') (2.97, 3.05, 'u') (3.05, 3.11, 'ɾ') (3.11, 3.19, 'o')\n",
      " (3.19, 3.22, 'n') (3.22, 3.32, 'o') (3.32, 3.4 , 't') (3.4 , 3.56, 'ɔ')\n",
      " (3.56, 3.63, 'l') (3.63, 3.74, 't') (3.74, 3.83, 'e') (3.83, 4.46, '.')]\n",
      "IPA Phones: 39\n",
      "Ternary Phones: torch.Size([25, 39])\n"
     ]
    }
   ],
   "source": [
    "ipawords_list = ['%'.join([elem[2] for elem in ipa_phnm3])]\n",
    "ternary_emb_phnm = ipa_to_ternary(ipawords_list, merge_diphtongues=True)\n",
    "ternary_emb_phnm = torch.FloatTensor(ternary_emb_phnm).T \n",
    "print(f\"Sentence: {sentence}\")\n",
    "print(f\"IPA Phones: {ipa_phnm3}\")\n",
    "print(f\"IPA Phones: {len(ipa_phnm3)}\")\n",
    "print(f\"Ternary Phones: {ternary_emb_phnm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "114ea78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb shape: (2, 25)\n",
      "Invalid IPA: nf for MPSKA phone nf\n"
     ]
    }
   ],
   "source": [
    "for k, v in mspka2ipa.items():\n",
    "    emb = ipa_to_ternary([v], merge_diphtongues=True)\n",
    "    if emb.shape[0] != 1:\n",
    "        print(f\"emb shape: {emb.shape}\")\n",
    "        print(f\"Invalid IPA: {v} for MPSKA phone {k}\")\n",
    "        sentence = get_mspka_sentence(lab_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29d6d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "phnm3s = []\n",
    "for lab_file in mspka_lab_files:\n",
    "    sentence = get_mspka_sentence(lab_file)[0]\n",
    "    phnm3 = get_mspka_phnm3(lab_file)\n",
    "    truc = False\n",
    "    for s, e, phone in phnm3:\n",
    "        emb = ipa_to_ternary([phone], merge_diphtongues=True)\n",
    "        if phone != \".\" and emb.shape[0] != 1:\n",
    "            print(f\"Invalid IPA: {phone} in file {lab_file.name}\")\n",
    "            print(sentence)\n",
    "            truc = True\n",
    "    if truc:\n",
    "        sentences.append(sentence)\n",
    "        phnm3s.append(phnm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e77209",
   "metadata": {},
   "source": [
    "## PB2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b662e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_dir =  DATA_DIR / 'pb2007'\n",
    "pb_phone_files = sorted(list(pb_dir.glob('*.phone')))\n",
    "\n",
    "from utils_dataset.pb2007 import pb20072ipa, get_pb2007_phnm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb63468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pb2007_phnm3_ori(phone_file: str) -> np.ndarray:\n",
    "    with open(phone_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "    lines = [line.split(\" \") for line in lines]\n",
    "\n",
    "    phnm3 = []\n",
    "    for line in lines:\n",
    "        if len(line) == 3:\n",
    "            s_frame, e_frame, phone = line\n",
    "            s_sec = float(s_frame) / 100\n",
    "            e_sec = float(e_frame) / 100\n",
    "            phnm3.append((s_sec, e_sec, phone))\n",
    "    phnm3 = [(s, e, phone) for s, e, phone in phnm3]\n",
    "    phnm3 = np.array(phnm3, dtype=[(\"start\", \"f4\"), (\"end\", \"f4\"), (\"phone\", \"U10\")])\n",
    "    return phnm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed9a326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "phnm3s = []\n",
    "phone_files = []\n",
    "for phone_file in pb_phone_files:\n",
    "    phnm3 = get_pb2007_phnm3_ori(phone_file)\n",
    "    truc=False\n",
    "    for s, e, phone in phnm3:\n",
    "        if phone == \"e~\":\n",
    "            truc = True\n",
    "        #if (phone not in [\".\", \"..\"]) and not ft.validate_word(phone):\n",
    "        #    print(f\"Invalid IPA: {phone} in file {phone_file.name}\")\n",
    "    if truc:\n",
    "        phnm3s.append(phnm3)\n",
    "        phone_files.append(phone_file)\n",
    "        #print(f\"Invalid IPA: {phone} in file {phone_file.name}\")\n",
    "        #print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94e4af78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phonemes: [(0.  , 0.15, '.') (0.15, 0.21, 'l') (0.21, 0.27, 'e') (0.27, 0.37, 'p')\n",
      " (0.37, 0.43, 'a') (0.43, 0.47, 'ʁ') (0.47, 0.53, 'a') (0.53, 0.58, 'm')\n",
      " (0.58, 0.67, 'ɛ') (0.67, 0.72, 't') (0.72, 0.8 , 'ʁ') (0.8 , 0.85, 'a')\n",
      " (0.85, 0.9 , 'ʁ') (0.9 , 1.  , 't') (1.  , 1.06, 'i') (1.06, 1.14, 'k')\n",
      " (1.14, 1.19, 'y') (1.19, 1.23, 'l') (1.23, 1.29, 'a') (1.29, 1.42, 't')\n",
      " (1.42, 1.48, 'w') (1.48, 1.6 , 'a') (1.6 , 1.65, 'ʁ') (1.65, 1.77, 'k')\n",
      " (1.77, 1.82, 'i') (1.82, 1.92, 'p') (1.92, 1.98, 'i') (1.98, 2.05, 'l')\n",
      " (2.05, 2.14, 'ɔ') (2.14, 2.24, 't') (2.24, 2.31, 'ɑ̃') (2.31, 2.44, 's')\n",
      " (2.44, 2.5 , 'm') (2.5 , 2.57, 'ɔ') (2.57, 2.66, 'm') (2.66, 2.83, 'ɑ̃')\n",
      " (2.83, 2.94, 'm') (2.94, 3.  , 'a') (3.  , 3.06, 'm') (3.06, 3.13, 'a')\n",
      " (3.13, 3.28, 'ʃ') (3.28, 3.38, 'w') (3.38, 3.56, 'a') (3.56, 3.7 , 'ʁ')\n",
      " (3.7 , 3.78, '.') (3.78, 3.85, 'm') (3.85, 3.95, 'a') (3.95, 4.04, 'l')\n",
      " (4.04, 4.2 , 'ɑ̃') (4.2 , 4.32, 'ɡ') (4.32, 4.42, 'e') (4.42, 4.5 , 'm')\n",
      " (4.5 , 4.56, 'ɛ') (4.56, 4.64, 'l') (4.64, 4.8 , 'ɛ') (4.8 , 4.88, 'v')\n",
      " (4.88, 5.  , 'ʁ') (5.  , 5.09, 'ɔ̃') (5.09, 5.16, 't') (5.16, 5.22, 'e')\n",
      " (5.22, 5.31, 't') (5.31, 5.39, 'e') (5.39, 5.46, '.') (5.46, 5.59, 'ɑ̃')\n",
      " (5.59, 5.65, 'ʁ') (5.65, 5.73, 'ø') (5.73, 5.78, 'ʒ') (5.78, 5.82, 'i')\n",
      " (5.82, 5.92, 's') (5.92, 5.98, 't') (5.98, 6.04, 'ʁ') (6.04, 6.19, 'e')\n",
      " (6.19, 6.35, '.')]\n",
      "IPA Phones: [(0.  , 0.15, '.') (0.15, 0.21, 'l') (0.21, 0.27, 'e') (0.27, 0.37, 'p')\n",
      " (0.37, 0.43, 'a') (0.43, 0.47, 'ʁ') (0.47, 0.53, 'a') (0.53, 0.58, 'm')\n",
      " (0.58, 0.67, 'ɛ') (0.67, 0.72, 't') (0.72, 0.8 , 'ʁ') (0.8 , 0.85, 'a')\n",
      " (0.85, 0.9 , 'ʁ') (0.9 , 1.  , 't') (1.  , 1.06, 'i') (1.06, 1.14, 'k')\n",
      " (1.14, 1.19, 'y') (1.19, 1.23, 'l') (1.23, 1.29, 'a') (1.29, 1.42, 't')\n",
      " (1.42, 1.48, 'w') (1.48, 1.6 , 'a') (1.6 , 1.65, 'ʁ') (1.65, 1.77, 'k')\n",
      " (1.77, 1.82, 'i') (1.82, 1.92, 'p') (1.92, 1.98, 'i') (1.98, 2.05, 'l')\n",
      " (2.05, 2.14, 'ɔ') (2.14, 2.24, 't') (2.24, 2.31, 'ɑ̃') (2.31, 2.44, 's')\n",
      " (2.44, 2.5 , 'm') (2.5 , 2.57, 'ɔ') (2.57, 2.66, 'm') (2.66, 2.83, 'ɑ̃')\n",
      " (2.83, 2.94, 'm') (2.94, 3.  , 'a') (3.  , 3.06, 'm') (3.06, 3.13, 'a')\n",
      " (3.13, 3.28, 'ʃ') (3.28, 3.38, 'w') (3.38, 3.56, 'a') (3.56, 3.7 , 'ʁ')\n",
      " (3.7 , 3.78, '.') (3.78, 3.85, 'm') (3.85, 3.95, 'a') (3.95, 4.04, 'l')\n",
      " (4.04, 4.2 , 'ɑ̃') (4.2 , 4.32, 'ɡ') (4.32, 4.42, 'e') (4.42, 4.5 , 'm')\n",
      " (4.5 , 4.56, 'ɛ') (4.56, 4.64, 'l') (4.64, 4.8 , 'ɛ') (4.8 , 4.88, 'v')\n",
      " (4.88, 5.  , 'ʁ') (5.  , 5.09, 'ɔ̃') (5.09, 5.16, 't') (5.16, 5.22, 'e')\n",
      " (5.22, 5.31, 't') (5.31, 5.39, 'e') (5.39, 5.46, '.') (5.46, 5.59, 'ɑ̃')\n",
      " (5.59, 5.65, 'ʁ') (5.65, 5.73, 'ø') (5.73, 5.78, 'ʒ') (5.78, 5.82, 'i')\n",
      " (5.82, 5.92, 's') (5.92, 5.98, 't') (5.98, 6.04, 'ʁ') (6.04, 6.19, 'e')\n",
      " (6.19, 6.35, '.')]\n",
      "IPA Phones: 73\n",
      "Ternary Phones: torch.Size([25, 73])\n"
     ]
    }
   ],
   "source": [
    "phone_file = pb_phone_files[-1]  # Example phone file\n",
    "ipa_phnm3 = get_pb2007_phnm3(phone_file)\n",
    "print(f\"Phonemes: {ipa_phnm3}\")\n",
    "ipawords_list = ['%'.join([elem[2] for elem in ipa_phnm3])]\n",
    "ternary_emb_phnm = ipa_to_ternary(ipawords_list, merge_diphtongues=True)\n",
    "ternary_emb_phnm = torch.FloatTensor(ternary_emb_phnm).T \n",
    "print(f\"IPA Phones: {ipa_phnm3}\")\n",
    "print(f\"IPA Phones: {len(ipa_phnm3)}\")\n",
    "print(f\"Ternary Phones: {ternary_emb_phnm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a3b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in pb20072ipa.items():\n",
    "    emb = ipa_to_ternary([v], merge_diphtongues=True)\n",
    "    if emb.shape[0] != 1:\n",
    "        print(f\"emb shape: {emb.shape}\")\n",
    "        print(f\"Invalid IPA: {v} for MPSKA phone {k}\")µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b17020b",
   "metadata": {},
   "source": [
    "## LJSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ce8582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import params_v1\n",
    "\n",
    "merge_diphtongues = params_v1.merge_diphtongues\n",
    "cmudict_path = \"resources/cmu_dictionary\"\n",
    "dictionary_cmu = cmudict.CMUDict(cmudict_path)\n",
    "\n",
    "def get_phonemes(\n",
    "        text: str, add_blank: bool = False, #False to uniformize with other aligned datasets not using blanks\n",
    "    ) -> torch.IntTensor:  # shape: (n_ipa_feats, seq_len)\n",
    "    ipawords_list = text_to_ipa(\n",
    "        text,\n",
    "        dictionary=dictionary_cmu,\n",
    "        cleaner_names=[\"english_cleaners_v2\"],\n",
    "        remove_punctuation=True, # Remove punctuation from the text to uniformize with other aligned datasets\n",
    "    )\n",
    "    if add_blank:\n",
    "        ipawords_list = intersperse(ipawords_list, \" \")\n",
    "    phnm_string = '%'.join(ipawords_list)\n",
    "    phnm_string = \".%\" + phnm_string + \"%.\"\n",
    "    return phnm_string.split(\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564912fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from paths import FILELISTS_DIR\n",
    "#\n",
    "#filelist_fp = FILELISTS_DIR / \"ljspeech\" / \"valid_v0.txt\"\n",
    "#lines = parse_filelist(filelist_fp)\n",
    "#save_dir = DATA_DIR / \"LJSpeech-1.1\" / \"phnm3\"\n",
    "#for fp, text in lines:\n",
    "#    filestem = Path(fp).stem\n",
    "#    ipawords_list = get_phonemes(text, add_blank=False)\n",
    "#    phnm3_name = filestem + \"_phnm3.npy\"\n",
    "#    phones = []\n",
    "#    for phone in ipawords_list:\n",
    "#        start_time = float(\"nan\")\n",
    "#        end_time = float(\"nan\")\n",
    "#        phones.append((start_time, end_time, phone))\n",
    "#    phones = np.array(phones, dtype=[(\"start\", \"f4\"), (\"end\", \"f4\"), (\"phone\", \"U10\")])\n",
    "#    phnm3_fp = save_dir / phnm3_name\n",
    "#    np.save(phnm3_fp, phones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d302a8b1",
   "metadata": {},
   "source": [
    "## Dataset, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22b8a793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size 10 valid_size 10\n"
     ]
    }
   ],
   "source": [
    "from data_phnm import PhnmArticDataset, PhnmArticBatchCollate\n",
    "from torch.utils.data import DataLoader\n",
    "from paths import DATA_DIR\n",
    "\n",
    "from configs import params_v1\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_dataset = PhnmArticDataset(\n",
    "        params_v1.train_filelist_path,\n",
    "        data_root_dir=DATA_DIR,\n",
    "        load_coder=False,\n",
    "        shuffle=False,\n",
    "        merge_diphtongues=True,\n",
    "    )\n",
    "valid_dataset = PhnmArticDataset(\n",
    "        params_v1.valid_filelist_path,\n",
    "        data_root_dir=DATA_DIR,\n",
    "        load_coder=False,\n",
    "        shuffle=False,\n",
    "        merge_diphtongues=True,\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataset.filepaths_list = train_dataset.filepaths_list[:10]\n",
    "valid_dataset.filepaths_list = valid_dataset.filepaths_list[:10]\n",
    "print(\"train_size\", len(train_dataset), \"valid_size\", len(valid_dataset))\n",
    "\n",
    "batch_collate = PhnmArticBatchCollate()\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=batch_collate,\n",
    "    drop_last=True,\n",
    "    shuffle=False,\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=batch_collate,\n",
    "    drop_last=True,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00ab1586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[[ 0.,  1., -1.,  ..., -1., -1.,  0.],\n",
       "          [ 0.,  1., -1.,  ...,  1., -1.,  0.],\n",
       "          [ 0., -1.,  1.,  ...,  1.,  1.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "          [ 1.,  0.,  0.,  ...,  0.,  0.,  1.]]]),\n",
       " 'x_lengths': tensor([120]),\n",
       " 'y': tensor([[[-1.4232, -1.1987, -1.1778,  ..., -0.6045, -0.4897, -0.5133],\n",
       "          [-1.6910, -1.7874, -1.8012,  ..., -0.5524, -0.4178, -0.3054],\n",
       "          [-1.9739, -2.0031, -2.0324,  ..., -0.9943, -0.7880, -0.4183],\n",
       "          ...,\n",
       "          [ 0.0038,  0.9296,  1.5182,  ...,  0.0295,  0.0187,  0.0164],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.2512,  1.2418,  1.4047,  ...,  2.1459,  2.1791,  2.2276]]]),\n",
       " 'y_lengths': tensor([492])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truc = next(iter(train_loader))\n",
    "truc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82431e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from model import GradTTS\n",
    "from configs import params_v0\n",
    "\n",
    "model = GradTTS(\n",
    "        params_v0.n_ipa_feats,\n",
    "        params_v0.n_spks,\n",
    "        None if params_v0.n_spks == 1 else params_v0.spk_emb_dim, #spk_emb_dim\n",
    "        params_v0.n_enc_channels,\n",
    "        params_v0.filter_channels,\n",
    "        params_v0.filter_channels_dp,\n",
    "        params_v0.n_heads,\n",
    "        params_v0.n_enc_layers,\n",
    "        params_v0.enc_kernel,\n",
    "        params_v0.enc_dropout,\n",
    "        params_v0.window_size,\n",
    "        params_v0.n_feats,\n",
    "        params_v0.dec_dim,\n",
    "        params_v0.beta_min,\n",
    "        params_v0.beta_max,\n",
    "        params_v0.pe_scale,\n",
    "    )\n",
    "\n",
    "version = 'v0_es_ema_200'\n",
    "grad_filename = 'grad_10.pt'\n",
    "ckpt_state_dict = torch.load(LOGS_DIR / version / grad_filename,\n",
    "                  map_location=torch.device('cpu'))\n",
    "model.load_state_dict(ckpt_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b044fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, item in enumerate(valid_loader):\n",
    "        x = item[\"x\"].to(torch.float32)\n",
    "        x_lengths = torch.LongTensor([x.shape[-1]])\n",
    "        y_enc, y_dec, attn = model(x, x_lengths, n_timesteps=50)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a7415a",
   "metadata": {},
   "source": [
    "## Never know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d691e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mngu0_dir = LJLISTS_DIR / \"../mngu0\"\n",
    "#mocha_dir = LJLISTS_DIR / \"../mocha\"\n",
    "#mspka_dir = LJLISTS_DIR / \"../mspka\"\n",
    "#pb2007_dir = LJLISTS_DIR / \"../pb2007\"\n",
    "#\n",
    "#flist_dir = pb2007_dir\n",
    "#\n",
    "#with open(flist_dir / \"file_list.txt\", \"r\") as f:\n",
    "#    lines = [line.strip() for line in f.readlines()]\n",
    "#\n",
    "#data_prefix = \"DUMMY/\"\n",
    "#data_prefix += \"pb2007\" # or \"mocha_timit\" or \"MSPKA_EMA_ita\" or \"pb2007\"\n",
    "#data_prefix += \"/arttts\"\n",
    "#\n",
    "#new_lines = []\n",
    "#for line in lines:\n",
    "#    _, spk, phnm3, filename = line.split(\"/\")\n",
    "#    spk_prefix = data_prefix + \"/\" + spk\n",
    "#    phnm3_prefix = spk_prefix + \"/phnm3\"\n",
    "#    phnm3_fp = phnm3_prefix +\"/\" + filename\n",
    "#    wav_fp = spk_prefix + \"/wavs\" + \"/\" + filename.replace(\"_phnm3.npy\", \".wav\")\n",
    "#    new_line = f\"{wav_fp}|{phnm3_fp}\"\n",
    "#    new_lines.append(new_line)\n",
    "#new_lines = sorted(new_lines)\n",
    "#\n",
    "#with open(flist_dir / \"total_v1.txt\", \"w\") as f:\n",
    "#    for line in new_lines:\n",
    "#        f.write(line + \"\\n\")\n",
    "#print(f\"Total lines: {len(new_lines)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fd5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#\n",
    "#dataset = \"pb2007\"\n",
    "#for speaker in [\"spk1\"]:\n",
    "#    with open(f\"resources/filelists/{dataset}/total_v1.txt\", \"r\") as f:\n",
    "#        total_v1 = f.read().splitlines()\n",
    "#    total_v1 = np.array(total_v1)\n",
    "#    speakers = np.array([e.split(\"/\")[3] for e in total_v1])\n",
    "#    speaker_v1 = total_v1[np.where(np.array(speakers) == speaker)[0]]\n",
    "#\n",
    "#    with open(f\"resources/filelists/{dataset}/{speaker}_v1.txt\", \"w\") as file:\n",
    "#        file.writelines([e + '\\n' for e in speaker_v1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
