{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9285a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import DATA_DIR, LJLISTS_DIR, LOGS_DIR, FILELISTS_DIR\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from text import cmudict\n",
    "from utils import parse_filelist, intersperse\n",
    "\n",
    "from text.converters import ipa_to_ternary, text_to_ipa, traits_list\n",
    "from panphon import FeatureTable\n",
    "\n",
    "ft = FeatureTable()\n",
    "\n",
    "cmudict_path = \"resources/cmu_dictionary\"\n",
    "dictionary_cmu = cmudict.CMUDict(cmudict_path)\n",
    "cleaner_names = [\"english_cleaners_v2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff82c3e",
   "metadata": {},
   "source": [
    "## MNGU0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc0556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mngu0_dir = DATA_DIR / 'MNGU0' / \"src_data\" / \"s1\" / \"phone_labels\"\n",
    "\n",
    "utt_files = sorted(list(mngu0_dir.glob('*.utt')))\n",
    "lab_files = sorted(list(mngu0_dir.glob('*.lab')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab204819",
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_file = utt_files[0]  # Example utt file\n",
    "lab_file = lab_files[0]  # Example lab file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7ecc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_dataset.mngu0 import mngu02ipa, get_mngu0_sentence, get_mngu0_phnm3\n",
    "\n",
    "sentence = get_mngu0_sentence(utt_file)\n",
    "ipa_phnm3 = get_mngu0_phnm3(lab_file) # norm\n",
    "ipawords_list = ['%'.join([elem[2] for elem in ipa_phnm3])]\n",
    "ternary_emb_phnm = ipa_to_ternary(ipawords_list, merge_diphtongues=True)\n",
    "ternary_emb_phnm = torch.FloatTensor(ternary_emb_phnm).T \n",
    "print(f\"Sentence: {sentence}\")\n",
    "print(f\"IPA Phones: {ipa_phnm3}\")\n",
    "print(f\"IPA Phones: {len(ipa_phnm3)}\")\n",
    "print(f\"Ternary Phones: {ternary_emb_phnm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c53b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = sentence\n",
    "add_blank = False  # Whether to add a blank token between IPA symbols\n",
    "merge_diphtongues = True  # Whether to merge diphthongs into single symbols\n",
    "\n",
    "ipawords_list = text_to_ipa(\n",
    "    text,\n",
    "    dictionary=dictionary_cmu,\n",
    "    cleaner_names=[\"english_cleaners_v2\"],\n",
    "    remove_punctuation=False,\n",
    ")\n",
    "if add_blank:\n",
    "    ipawords_list = intersperse(ipawords_list, \" \")\n",
    "ternary_emb = ipa_to_ternary(\n",
    "    ipawords_list, merge_diphtongues=merge_diphtongues\n",
    ")\n",
    "ternary_emb = torch.FloatTensor(ternary_emb).T  # shape: (n_ipa_feats, seq_len)\n",
    "ternary_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d923fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in mngu02ipa.items():\n",
    "    emb = ipa_to_ternary([v], merge_diphtongues=True)\n",
    "    if emb.shape[0] != 1:\n",
    "        print(f\"emb shape: {emb.shape}\")\n",
    "        print(f\"Invalid IPA: {v} for MNGU0 phone {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc0980e",
   "metadata": {},
   "source": [
    "## Mocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4225a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mocha_dir = DATA_DIR / 'mocha_timit'\n",
    "mocha_trans_files = sorted(list(mocha_dir.glob('*.trans')))\n",
    "mocha_phnm_files = sorted(list(mocha_dir.glob('*.phnm')))\n",
    "\n",
    "trans_file = mocha_trans_files[0]  # Example trans file\n",
    "phnm_file = mocha_phnm_files[0]  # Example phnm file\n",
    "\n",
    "from utils_dataset.mocha import get_mocha_sentence, get_mocha_phnm3\n",
    "\n",
    "sentence = get_mocha_sentence(trans_file)\n",
    "ipa_phnm3 = get_mocha_phnm3(phnm_file)\n",
    "print(f\"Sentence: {sentence}\")\n",
    "print(f\"Phonemes: {ipa_phnm3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6fe55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipawords_list = ['%'.join([elem[2] for elem in ipa_phnm3])]\n",
    "ternary_emb_phnm = ipa_to_ternary(ipawords_list, merge_diphtongues=True)\n",
    "ternary_emb_phnm = torch.FloatTensor(ternary_emb_phnm).T \n",
    "print(f\"Sentence: {sentence}\")\n",
    "print(f\"IPA Phones: {ipa_phnm3}\")\n",
    "print(f\"IPA Phones: {len(ipa_phnm3)}\")\n",
    "print(f\"Ternary Phones: {ternary_emb_phnm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a709e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = sentence\n",
    "add_blank = False  # Whether to add a blank token between IPA symbols\n",
    "merge_diphtongues = True  # Whether to merge diphthongs into single symbols\n",
    "\n",
    "ipawords_list = text_to_ipa(\n",
    "    text,\n",
    "    dictionary=dictionary_cmu,\n",
    "    cleaner_names=[\"english_cleaners_v2\"],\n",
    "    remove_punctuation=False,\n",
    ")\n",
    "if add_blank:\n",
    "    ipawords_list = intersperse(ipawords_list, \" \")\n",
    "ternary_emb = ipa_to_ternary(\n",
    "    ipawords_list, merge_diphtongues=merge_diphtongues\n",
    ")\n",
    "ternary_emb = torch.FloatTensor(ternary_emb).T  # shape: (n_ipa_feats, seq_len)\n",
    "ternary_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonems = set()\n",
    "mocha_phnm_files = sorted(list(mocha_dir.glob('*arttts/*/phnm3/*_phnm3.npy')))\n",
    "for phnm_file in mocha_phnm_files:\n",
    "    #phnm3 = get_mocha_phnm3(phnm_file)\n",
    "    phnm3 = np.load(phnm_file)\n",
    "    for s, e, phone in phnm3:\n",
    "        phonems.add(phone)\n",
    "        if phone != \".\" and not ft.validate_word(phone):\n",
    "            print(f\"Invalid IPA: {phone} in file {phnm_file.name}\")\n",
    "        #emb = ipa_to_ternary([phone], merge_diphtongues=True)\n",
    "        #if emb.shape[0] != 1:\n",
    "        #    print(f\"emb shape: {emb.shape}\")\n",
    "        #    print(f\"Invalid IPA: {phone} in file {phnm_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a381930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in phonems:\n",
    "    emb = ipa_to_ternary([v], merge_diphtongues=True)\n",
    "    if emb.shape[0] != 1:\n",
    "        print(f\"emb shape: {emb.shape}\")\n",
    "        print(f\"Invalid IPA: {v} for MNGU0 phone {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae5f4af",
   "metadata": {},
   "source": [
    "## MSPKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf1d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_dataset.mspka import get_mspka_sentence, get_mspka_phnm3, mspka2ipa\n",
    "\n",
    "mspka_dir = DATA_DIR / 'MSPKA_EMA_ita'\n",
    "mspka_lab_files = sorted(list(mspka_dir.glob('*.lab')))\n",
    "mspka_sent_files = sorted(list(mspka_dir.glob('list_sentences')))\n",
    "\n",
    "lab_file = mspka_lab_files[0]  # Example lab file\n",
    "sent_file = mspka_sent_files[0]  # Example phnm file\n",
    "\n",
    "sentence = get_mspka_sentence(sent_file)\n",
    "ipa_phnm3 = get_mspka_phnm3(lab_file)\n",
    "\n",
    "#with open(sent_file, 'r', encoding='utf-8') as f:\n",
    "#    sentence = f.read().strip()\n",
    "#print(f\"Sentence from file: {sentence}\")\n",
    "\n",
    "#mspka_phnms = set()\n",
    "#\n",
    "#for lab_file in mspka_lab_files:\n",
    "#    sent, phnm3 = get_mspka_sentence_phnm3(lab_file)\n",
    "#    for s, e, phone in phnm3:\n",
    "#        mspka_phnms.add(phone)\n",
    "#mspka_phnms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab_file in mspka_lab_files:\n",
    "    sentence = get_mspka_sentence(lab_file)[0]\n",
    "    phnm3 = get_mspka_phnm3(lab_file)\n",
    "    for s, e, phone in phnm3:\n",
    "        if phone != \".\" and not ft.validate_word(phone):\n",
    "            print(f\"Invalid IPA: {phone} in file {lab_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5027465",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipawords_list = ['%'.join([elem[2] for elem in ipa_phnm3])]\n",
    "ternary_emb_phnm = ipa_to_ternary(ipawords_list, merge_diphtongues=True)\n",
    "ternary_emb_phnm = torch.FloatTensor(ternary_emb_phnm).T \n",
    "print(f\"Sentence: {sentence}\")\n",
    "print(f\"IPA Phones: {ipa_phnm3}\")\n",
    "print(f\"IPA Phones: {len(ipa_phnm3)}\")\n",
    "print(f\"Ternary Phones: {ternary_emb_phnm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ea78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in mspka2ipa.items():\n",
    "    emb = ipa_to_ternary([v], merge_diphtongues=True)\n",
    "    if emb.shape[0] != 1:\n",
    "        print(f\"emb shape: {emb.shape}\")\n",
    "        print(f\"Invalid IPA: {v} for MPSKA phone {k}\")\n",
    "        sentence = get_mspka_sentence(lab_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d6d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "phnm3s = []\n",
    "for lab_file in mspka_lab_files:\n",
    "    sentence = get_mspka_sentence(lab_file)[0]\n",
    "    phnm3 = get_mspka_phnm3(lab_file)\n",
    "    truc = False\n",
    "    for s, e, phone in phnm3:\n",
    "        emb = ipa_to_ternary([phone], merge_diphtongues=True)\n",
    "        if phone != \".\" and emb.shape[0] != 1:\n",
    "            print(f\"Invalid IPA: {phone} in file {lab_file.name}\")\n",
    "            print(sentence)\n",
    "            truc = True\n",
    "    if truc:\n",
    "        sentences.append(sentence)\n",
    "        phnm3s.append(phnm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e77209",
   "metadata": {},
   "source": [
    "## PB2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b662e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_dir =  DATA_DIR / 'pb2007'\n",
    "pb_phone_files = sorted(list(pb_dir.glob('*.phone')))\n",
    "\n",
    "from utils_dataset.pb2007 import pb20072ipa, get_pb2007_phnm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb63468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pb2007_phnm3_ori(phone_file: str) -> np.ndarray:\n",
    "    with open(phone_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "    lines = [line.split(\" \") for line in lines]\n",
    "\n",
    "    phnm3 = []\n",
    "    for line in lines:\n",
    "        if len(line) == 3:\n",
    "            s_frame, e_frame, phone = line\n",
    "            s_sec = float(s_frame) / 100\n",
    "            e_sec = float(e_frame) / 100\n",
    "            phnm3.append((s_sec, e_sec, phone))\n",
    "    phnm3 = [(s, e, phone) for s, e, phone in phnm3]\n",
    "    phnm3 = np.array(phnm3, dtype=[(\"start\", \"f4\"), (\"end\", \"f4\"), (\"phone\", \"U10\")])\n",
    "    return phnm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "phnm3s = []\n",
    "phone_files = []\n",
    "for phone_file in pb_phone_files:\n",
    "    phnm3 = get_pb2007_phnm3_ori(phone_file)\n",
    "    truc=False\n",
    "    for s, e, phone in phnm3:\n",
    "        if phone == \"e~\":\n",
    "            truc = True\n",
    "        #if (phone not in [\".\", \"..\"]) and not ft.validate_word(phone):\n",
    "        #    print(f\"Invalid IPA: {phone} in file {phone_file.name}\")\n",
    "    if truc:\n",
    "        phnm3s.append(phnm3)\n",
    "        phone_files.append(phone_file)\n",
    "        #print(f\"Invalid IPA: {phone} in file {phone_file.name}\")\n",
    "        #print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_file = pb_phone_files[-1]  # Example phone file\n",
    "ipa_phnm3 = get_pb2007_phnm3(phone_file)\n",
    "print(f\"Phonemes: {ipa_phnm3}\")\n",
    "ipawords_list = ['%'.join([elem[2] for elem in ipa_phnm3])]\n",
    "ternary_emb_phnm = ipa_to_ternary(ipawords_list, merge_diphtongues=True)\n",
    "ternary_emb_phnm = torch.FloatTensor(ternary_emb_phnm).T \n",
    "print(f\"IPA Phones: {ipa_phnm3}\")\n",
    "print(f\"IPA Phones: {len(ipa_phnm3)}\")\n",
    "print(f\"Ternary Phones: {ternary_emb_phnm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a3b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in pb20072ipa.items():\n",
    "    emb = ipa_to_ternary([v], merge_diphtongues=True)\n",
    "    if emb.shape[0] != 1:\n",
    "        print(f\"emb shape: {emb.shape}\")\n",
    "        print(f\"Invalid IPA: {v} for MPSKA phone {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b17020b",
   "metadata": {},
   "source": [
    "## LJSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce8582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import params_v1\n",
    "\n",
    "merge_diphtongues = params_v1.merge_diphtongues\n",
    "cmudict_path = \"resources/cmu_dictionary\"\n",
    "dictionary_cmu = cmudict.CMUDict(cmudict_path)\n",
    "\n",
    "def get_phonemes(\n",
    "        text: str, add_blank: bool = False, #False to uniformize with other aligned datasets not using blanks\n",
    "    ) -> torch.IntTensor:  # shape: (n_ipa_feats, seq_len)\n",
    "    ipawords_list = text_to_ipa(\n",
    "        text,\n",
    "        dictionary=dictionary_cmu,\n",
    "        cleaner_names=[\"english_cleaners_v2\"],\n",
    "        remove_punctuation=True, # Remove punctuation from the text to uniformize with other aligned datasets\n",
    "    )\n",
    "    if add_blank:\n",
    "        ipawords_list = intersperse(ipawords_list, \" \")\n",
    "    phnm_string = '%'.join(ipawords_list)\n",
    "    phnm_string = \".%\" + phnm_string + \"%.\"\n",
    "    return phnm_string.split(\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564912fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from paths import FILELISTS_DIR\n",
    "#\n",
    "#filelist_fp = FILELISTS_DIR / \"ljspeech\" / \"valid_v0.txt\"\n",
    "#lines = parse_filelist(filelist_fp)\n",
    "#save_dir = DATA_DIR / \"LJSpeech-1.1\" / \"phnm3\"\n",
    "#for fp, text in lines:\n",
    "#    filestem = Path(fp).stem\n",
    "#    ipawords_list = get_phonemes(text, add_blank=False)\n",
    "#    phnm3_name = filestem + \"_phnm3.npy\"\n",
    "#    phones = []\n",
    "#    for phone in ipawords_list:\n",
    "#        start_time = float(\"nan\")\n",
    "#        end_time = float(\"nan\")\n",
    "#        phones.append((start_time, end_time, phone))\n",
    "#    phones = np.array(phones, dtype=[(\"start\", \"f4\"), (\"end\", \"f4\"), (\"phone\", \"U10\")])\n",
    "#    phnm3_fp = save_dir / phnm3_name\n",
    "#    np.save(phnm3_fp, phones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d302a8b1",
   "metadata": {},
   "source": [
    "## Dataset, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b8a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_phnm import PhnmArticDataset, PhnmArticBatchCollate\n",
    "from torch.utils.data import DataLoader\n",
    "from paths import DATA_DIR\n",
    "\n",
    "from configs import params_v1\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_dataset = PhnmArticDataset(\n",
    "        params_v1.train_filelist_path,\n",
    "        data_root_dir=DATA_DIR,\n",
    "        load_coder=False,\n",
    "        shuffle=False,\n",
    "        merge_diphtongues=True,\n",
    "    )\n",
    "valid_dataset = PhnmArticDataset(\n",
    "        params_v1.valid_filelist_path,\n",
    "        data_root_dir=DATA_DIR,\n",
    "        load_coder=False,\n",
    "        shuffle=False,\n",
    "        merge_diphtongues=True,\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataset.filepaths_list = train_dataset.filepaths_list[:10]\n",
    "valid_dataset.filepaths_list = valid_dataset.filepaths_list[:10]\n",
    "print(\"train_size\", len(train_dataset), \"valid_size\", len(valid_dataset))\n",
    "\n",
    "batch_collate = PhnmArticBatchCollate()\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=batch_collate,\n",
    "    drop_last=True,\n",
    "    shuffle=False,\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=batch_collate,\n",
    "    drop_last=True,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82431e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import ArtTTS\n",
    "from configs import params_v0\n",
    "\n",
    "model = ArtTTS(\n",
    "        params_v0.n_ipa_feats,\n",
    "        params_v0.n_spks,\n",
    "        None if params_v0.n_spks == 1 else params_v0.spk_emb_dim, #spk_emb_dim\n",
    "        params_v0.n_enc_channels,\n",
    "        params_v0.filter_channels,\n",
    "        params_v0.filter_channels_dp,\n",
    "        params_v0.n_heads,\n",
    "        params_v0.n_enc_layers,\n",
    "        params_v0.enc_kernel,\n",
    "        params_v0.enc_dropout,\n",
    "        params_v0.window_size,\n",
    "        params_v0.n_feats,\n",
    "        params_v0.dec_dim,\n",
    "        params_v0.beta_min,\n",
    "        params_v0.beta_max,\n",
    "        params_v0.pe_scale,\n",
    "    )\n",
    "\n",
    "version = 'v0_es_ema_200'\n",
    "grad_filename = 'grad_10.pt'\n",
    "ckpt_state_dict = torch.load(LOGS_DIR / version / grad_filename,\n",
    "                  map_location=torch.device('cpu'))\n",
    "model.load_state_dict(ckpt_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, item in enumerate(valid_loader):\n",
    "        x = item[\"x\"].to(torch.float32)\n",
    "        x_lengths = torch.LongTensor([x.shape[-1]])\n",
    "        y_enc, y_dec, attn = model(x, x_lengths, n_timesteps=50)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a7415a",
   "metadata": {},
   "source": [
    "## Never know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d691e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mngu0_dir = LJLISTS_DIR / \"../mngu0\"\n",
    "#mocha_dir = LJLISTS_DIR / \"../mocha\"\n",
    "#mspka_dir = LJLISTS_DIR / \"../mspka\"\n",
    "#pb2007_dir = LJLISTS_DIR / \"../pb2007\"\n",
    "#\n",
    "#flist_dir = pb2007_dir\n",
    "#\n",
    "#with open(flist_dir / \"file_list.txt\", \"r\") as f:\n",
    "#    lines = [line.strip() for line in f.readlines()]\n",
    "#\n",
    "#data_prefix = \"DUMMY/\"\n",
    "#data_prefix += \"pb2007\" # or \"mocha_timit\" or \"MSPKA_EMA_ita\" or \"pb2007\"\n",
    "#data_prefix += \"/arttts\"\n",
    "#\n",
    "#new_lines = []\n",
    "#for line in lines:\n",
    "#    _, spk, phnm3, filename = line.split(\"/\")\n",
    "#    spk_prefix = data_prefix + \"/\" + spk\n",
    "#    phnm3_prefix = spk_prefix + \"/phnm3\"\n",
    "#    phnm3_fp = phnm3_prefix +\"/\" + filename\n",
    "#    wav_fp = spk_prefix + \"/wavs\" + \"/\" + filename.replace(\"_phnm3.npy\", \".wav\")\n",
    "#    new_line = f\"{wav_fp}|{phnm3_fp}\"\n",
    "#    new_lines.append(new_line)\n",
    "#new_lines = sorted(new_lines)\n",
    "#\n",
    "#with open(flist_dir / \"total_v1.txt\", \"w\") as f:\n",
    "#    for line in new_lines:\n",
    "#        f.write(line + \"\\n\")\n",
    "#print(f\"Total lines: {len(new_lines)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fd5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#\n",
    "#dataset = \"pb2007\"\n",
    "#for speaker in [\"spk1\"]:\n",
    "#    with open(f\"resources/filelists/{dataset}/total_v1.txt\", \"r\") as f:\n",
    "#        total_v1 = f.read().splitlines()\n",
    "#    total_v1 = np.array(total_v1)\n",
    "#    speakers = np.array([e.split(\"/\")[3] for e in total_v1])\n",
    "#    speaker_v1 = total_v1[np.where(np.array(speakers) == speaker)[0]]\n",
    "#\n",
    "#    with open(f\"resources/filelists/{dataset}/{speaker}_v1.txt\", \"w\") as file:\n",
    "#        file.writelines([e + '\\n' for e in speaker_v1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
